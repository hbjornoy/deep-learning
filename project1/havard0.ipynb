{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproject 1\n",
    "Fingermovements predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**///////////// TODO //////////////**\n",
    "- convnet\n",
    "- LSTM from slides\n",
    "- gru from slides\n",
    "- covnet wit dilution like class\n",
    "\n",
    "\n",
    "** /////////// immidiate todo ////////////////**\n",
    "- continue with LSTM\n",
    "    - maybe need to give hidden in every iteration.\n",
    "    - make new train(function) for lstm\n",
    "    - 1,50,1 is a problem how to give one class? (maybe last linearlayer?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import numpy as np\n",
    "from math import log10\n",
    "import dlc_bci as bci\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Our own code\n",
    "import helpers as HL\n",
    "import models as ML\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data format: \n",
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n",
      "Modified train_data.data_tensor shape:  torch.Size([316, 28, 50])\n",
      "Modified train_data.target_tensor shape:  torch.Size([316, 2])\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = HL.import_data(flatten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new models if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SenseNet(input_dim, output_dim, nb_hidden_layers=1, hidden_width=100, dropout_rate=False):\n",
    "    \"\"\"\n",
    "    Fully connected feedforward neural net with adjustible, but uniform width of hidden layers and and adjustable depth\n",
    "    \"\"\"\n",
    "    if nb_hidden_layers < 1:\n",
    "        print(\"you need at least one hidden layer\")\n",
    "        model = None\n",
    "    else:\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_width))\n",
    "        layers.append(nn.ReLU())\n",
    "        for i in range(nb_hidden_layers-1):\n",
    "            layers.append(nn.Linear(hidden_width, hidden_width))\n",
    "            layers.append(nn.ReLU())\n",
    "            if type(dropout_rate) == float and dropout_rate > 0.0 and dropout_rate < 1.0:\n",
    "                layers.append(nn.Dropout(p=dropout_rate))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_width, output_dim))\n",
    "        layers.append(nn.Softmax())\n",
    "\n",
    "        model = nn.Sequential(*layers)\n",
    "        return model\n",
    "\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_width, nb_layers, output_dim):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_width = hidden_width\n",
    "        self.nb_layers = nb_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_width, nb_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_width*2, output_dim)  # 2 for bidirection \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = Variable(torch.zeros(self.nb_layers*2, x.size(0), self.hidden_width)) # 2 for bidirection \n",
    "        c0 = Variable(torch.zeros(self.nb_layers*2, x.size(0), self.hidden_width))\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class conv_net1(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_width, nb_layers, output_dim):\n",
    "        super().__init__()\n",
    "        # makes 224 features out of the time series and 24 features\n",
    "        # feature making\n",
    "        self.conv1 = nn.Conv1d(input_dim, 56, kernel_size=4, stride=4, padding=0)\n",
    "        self.conv2 = nn.Conv1d(56, 112, kernel_size=3, stride=3, padding=0)\n",
    "        self.conv3 = nn.Conv1d(112, 224, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv4 = nn.Conv1d(224, 224, kernel_size=2, stride=1, padding=0)\n",
    "        \n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        #self.fc1 = torch.nn.Linear(18 * 16 * 16, 64)\n",
    "        \n",
    "        #64 input features, 10 output features for our 10 defined classes\n",
    "        self.fc1 = torch.nn.Linear(224, hidden_width)\n",
    "        self.r = nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_width, output_dim)\n",
    "        self.smax = torch.nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # feature making\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        \n",
    "        # remove redundant dimension before classification\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        \n",
    "        # classification\n",
    "        out = self.fc1(out)\n",
    "        out = self.r(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.smax(out)\n",
    "        return out\n",
    "    \n",
    "class conv_net2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_width, nb_layers, output_dim):\n",
    "        super().__init__()\n",
    "        # makes 224 features out of the time series and 24 features\n",
    "        # feature making\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 56, kernel_size=4, stride=4, padding=0),\n",
    "            nn.BatchNorm1d(56),\n",
    "            nn.ReLU())\n",
    "            #,nn.MaxPool1d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(56, 112, kernel_size=3, stride=3, padding=0),\n",
    "            nn.BatchNorm1d(112),\n",
    "            nn.ReLU())\n",
    "            #nn.MaxPool1d(2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(112, 224, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(224),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv1d(224, 224, kernel_size=2, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(224),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        \n",
    "        \n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        #self.fc1 = torch.nn.Linear(18 * 16 * 16, 64)\n",
    "        \n",
    "        #64 input features, 10 output features for our 10 defined classes\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(224, hidden_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_width, output_dim),\n",
    "            nn.Softmax(dim=0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # feature making\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        # remove redundant dimension before classification\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        \n",
    "        # classification\n",
    "        out = self.classification(out)\n",
    "        return out\n",
    "\n",
    "## TODO\n",
    "# - the batches fucked it up, fix it in the input.narrow() with s an t properly\n",
    "\n",
    "class rec_net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, rec_dim, internal_dim):\n",
    "        super().__init__()\n",
    "        self.fc_x2v = nn.Linear(input_dim, internal_dim) # train weights of how x(input) influence v(internal state)\n",
    "        self.fc_h2v = nn.Linear(rec_dim, internal_dim, bias= False) # why false bias here? train how (recurrent state) influence v(internal state)\n",
    "        self.fc_v2h = nn.Linear(internal_dim, rec_dim) # train how v(internal state) influence h(recurrent state)\n",
    "        self.fc_h2y = nn.Linear(rec_dim, output_dim) # train how to predict from h(recurrent state)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # initialize recurrent state with zeros in shape (1,output_dim)\n",
    "        h = Variable(input.data.new(1, self.fc_h2y.weight.size(1)).zero_())\n",
    "        \n",
    "        # loop through every sample in batch\n",
    "        for s in range(input.size(0)):\n",
    "            # initialize recurrent state with zeros in shape (1,output_dim)\n",
    "            h = Variable(input.data.new(1, self.fc_h2y.weight.size(1)).zero_())\n",
    "            \n",
    "            # loop through every part in sequence (first dim is \"time\")\n",
    "            for t in range(input.size(2)):\n",
    "                # t = data in that part of sequence,\n",
    "                # v = internal/hidden state, \n",
    "                # h = recurrent state\n",
    "                print(\"fc_x2v: \", self.fc_x2v)\n",
    "                print(\"h: \", h.shape)\n",
    "                print(\"self.fc_h2v(h): \", self.fc_h2v(h).shape)\n",
    "                print(\"input.narrow(0, t, 1): \", input.shape)\n",
    "                v = F.relu(self.fc_x2v(input[s].narrow(0, t, 1)) + self.fc_h2v(h))\n",
    "                print(\"v: \", v)\n",
    "                print(\"fc_v2h: \", self.fc_v2h)\n",
    "                h = self.fc_v2h(v)\n",
    "        # when to return???\n",
    "        # gotta store vector of predictions\n",
    "        return self.fc_h2y(h)\n",
    "    \n",
    "\n",
    "class recurrent_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def forward(self, input):  # ,hidden)\n",
    "        print(\"input: \", input[0,:,0].unsqueeze(dim=0).shape)\n",
    "        print(\"hidden: \", self.hidden.shape)\n",
    "        combined = torch.cat((input[0,:,0].unsqueeze(dim=0), self.hidden), 1)\n",
    "        self.hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([20, 28, 50])\n",
      "torch.Size([20, 56, 48])\n",
      "torch.Size([20, 56, 24])\n",
      "torch.Size([20, 112, 22])\n",
      "torch.Size([20, 112, 11])\n",
      "torch.Size([20, 224, 9])\n",
      "torch.Size([20, 224, 4])\n",
      "torch.Size([20, 224, 3])\n",
      "torch.Size([20, 224, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 224])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################# TESTING ##############################\n",
    "drit = nn.Conv1d(28, 56, 3, stride=1, padding=0)\n",
    "drit2 = torch.nn.Conv1d(56, 112, kernel_size=3, stride=1, padding=0)\n",
    "drit3 = nn.Conv1d(112, 224, kernel_size=3, stride=1, padding=0)\n",
    "drit4 = nn.Conv1d(224, 224, kernel_size=2, stride=1, padding=0)\n",
    "pul = nn.MaxPool1d(2)\n",
    "\n",
    "fack = Variable(torch.randn(20, 28, 50))\n",
    "print(\"input:\", fack.shape)\n",
    "output = drit(fack)\n",
    "print(output.shape)\n",
    "output = pul(output)\n",
    "print(output.shape)\n",
    "\n",
    "output = drit2(output)\n",
    "print(output.shape)\n",
    "output = pul(output)\n",
    "print(output.shape)\n",
    "\n",
    "output = drit3(output)\n",
    "print(output.shape)\n",
    "output = pul(output)\n",
    "print(output.shape)\n",
    "\n",
    "output = drit4(output)\n",
    "print(output.shape)\n",
    "output = pul(output)\n",
    "print(output.shape)\n",
    "#output = pul(output)\n",
    "#print(output.shape)\n",
    "\n",
    "\n",
    "output.view(output.shape[0],-1).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, dim_input, dim_recurrent, num_layers, dim_output):\n",
    "        super().__init__ ()\n",
    "        self.lstm = nn.LSTM(input_size = dim_input, hidden_size = dim_recurrent, num_layers = num_layers, batch_first=True)\n",
    "        self.fc_o2y = nn.Linear(dim_recurrent, dim_output)\n",
    "        \n",
    "    def forward (self, input):\n",
    "        # Makes this a batch of size 1\n",
    "        # The first index is the time , sequence number is the second\n",
    "        #print(\"input before: \", input.shape)\n",
    "        input.transpose_(1,2)\n",
    "        #input = input.unsqueeze(1)\n",
    "        #print(\"input after: \", input.shape)\n",
    "        # Get the activations of all layers at the last time step\n",
    "        output, _ = self.lstm(input)\n",
    "        # Drop the batch index\n",
    "        output = output.squeeze(1)\n",
    "        output = output.narrow(0, output.size(0)-1, 1)\n",
    "        prev_output = self.fc_o2y(F.relu(output))\n",
    "        #print(\"prev_output\", prev_output)\n",
    "        return F.softmax(prev_output, dim=2) # F.relu substituted with softmax\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model and define loss criterion and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  28\n",
      "output_dim:  2\n",
      "LSTM_net(\n",
      "  (lstm): LSTM(28, 111, batch_first=True)\n",
      "  (fc_o2y): Linear(in_features=111, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(train_data[0][0])\n",
    "output_dim = train_data.target_tensor.size(1)\n",
    "nb_hidden_layers = 3\n",
    "hidden_width = 500\n",
    "dropout_rate=0.4\n",
    "\n",
    "#input_dim=50 # for LSTM input dim might be the timedim\n",
    "\n",
    "print(\"input_dim: \", input_dim)\n",
    "print(\"output_dim: \", output_dim)\n",
    "\n",
    "# initialize the model\n",
    "densemodel_1 = ML.DenseNet(input_dim, output_dim, nb_hidden_layers, hidden_width, dropout_rate)\n",
    "linear_model = ML.Linear_regression_model(input_dim, output_dim)\n",
    "\n",
    "sensemodel = SenseNet(input_dim, output_dim, nb_hidden_layers, hidden_width, dropout_rate)\n",
    "birnn = BiRNN(input_dim, hidden_width, nb_hidden_layers, output_dim)\n",
    "conv_model1 = conv_net1(input_dim, hidden_width, nb_hidden_layers, output_dim)\n",
    "conv_model2 = conv_net2(input_dim, hidden_width, nb_hidden_layers, output_dim)\n",
    "rec_model = rec_net(input_dim, output_dim, 77, 77) # input_dim, output_dim, rec_dim, internal_dim)\n",
    "rnn_model = recurrent_net(input_dim, hidden_width, output_dim)\n",
    "lstm_model = LSTM_net(input_dim, dim_recurrent=111, num_layers=1, dim_output=output_dim)\n",
    "\n",
    "model = lstm_model\n",
    "\n",
    "# define loss criterion\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2  3\n",
      " 4  5  6\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\n",
       "  3\n",
       "  6\n",
       " [torch.FloatTensor of size 2x1], \n",
       "  2\n",
       "  2\n",
       " [torch.LongTensor of size 2x1])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbone = Tensor([[1,2,3],\n",
    "                [4,5,6]])\n",
    "print(tbone)\n",
    "tbone.topk(1) # return values in dim=? and index of max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainsamples:  316\n",
      "Number of testsamples:  100\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1593\n",
      "===> Prediction TRAIN-error: 0.0633\n",
      "===> Avg. PSNR: 9.8220 dB\n",
      "===> Prediction  TEST-error: 0.3600\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_0.pth -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/havardbjornoy/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type LSTM_net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 2 Complete: Avg. Loss: 0.1548\n",
      "===> Prediction TRAIN-error: 0.0570\n",
      "===> Avg. PSNR: 9.8833 dB\n",
      "===> Prediction  TEST-error: 0.3500\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_2.pth -------------------------------------\n",
      "===> Epoch 4 Complete: Avg. Loss: 0.1561\n",
      "===> Prediction TRAIN-error: 0.0665\n",
      "===> Avg. PSNR: 9.8574 dB\n",
      "===> Prediction  TEST-error: 0.3500\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_4.pth -------------------------------------\n",
      "===> Epoch 6 Complete: Avg. Loss: 0.1510\n",
      "===> Prediction TRAIN-error: 0.0633\n",
      "===> Avg. PSNR: 9.9247 dB\n",
      "===> Prediction  TEST-error: 0.3600\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_6.pth -------------------------------------\n",
      "===> Epoch 8 Complete: Avg. Loss: 0.1492\n",
      "===> Prediction TRAIN-error: 0.0601\n",
      "===> Avg. PSNR: 9.9429 dB\n",
      "===> Prediction  TEST-error: 0.3600\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_8.pth -------------------------------------\n",
      "===> Epoch 10 Complete: Avg. Loss: 0.1482\n",
      "===> Prediction TRAIN-error: 0.0601\n",
      "===> Avg. PSNR: 10.1338 dB\n",
      "===> Prediction  TEST-error: 0.3500\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_10.pth -------------------------------------\n",
      "===> Epoch 12 Complete: Avg. Loss: 0.1637\n",
      "===> Prediction TRAIN-error: 0.0665\n",
      "===> Avg. PSNR: 10.1346 dB\n",
      "===> Prediction  TEST-error: 0.3600\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_12.pth -------------------------------------\n",
      "===> Epoch 14 Complete: Avg. Loss: 0.1531\n",
      "===> Prediction TRAIN-error: 0.0665\n",
      "===> Avg. PSNR: 10.2656 dB\n",
      "===> Prediction  TEST-error: 0.3400\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_14.pth -------------------------------------\n",
      "===> Epoch 16 Complete: Avg. Loss: 0.1485\n",
      "===> Prediction TRAIN-error: 0.0570\n",
      "===> Avg. PSNR: 10.3200 dB\n",
      "===> Prediction  TEST-error: 0.3500\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_16.pth -------------------------------------\n",
      "===> Epoch 18 Complete: Avg. Loss: 0.1470\n",
      "===> Prediction TRAIN-error: 0.0570\n",
      "===> Avg. PSNR: 10.3704 dB\n",
      "===> Prediction  TEST-error: 0.3500\n",
      "Checkpoint: checkpoint_models/testingtesting_epoch_18.pth -------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_model = HL.train_model(train_data, test_data, model, criterion, learning_rate=0.0002, epochs=20, batch_size=1, checkpoint_name='testingtesting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some results\n",
    "conv_net1()\n",
    "- trained_model = HL.train_model(train_data, test_data, model, criterion, learning_rate=0.000006, epochs=50, batch_size=8, checkpoint_name='testingtesting')\n",
    "- hadde litt hÃ¸yere learningrate i starten, mye flere epochs\n",
    "\n",
    "===> Epoch 45 Complete: Avg. Loss: 0.0932\n",
    "===> Prediction TRAIN-error: 0.0063\n",
    "===> Avg. PSNR: -0.1346 dB\n",
    "===> Prediction  TEST-error: 0.2692\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test_data.target_tensor))\n",
    "values, indices = test_data.target_tensor.max(1)\n",
    "print(values, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
